╔════════════════════════════════════════════════════════════════════════════╗
║     BERT Mixed-Precision Quantization Framework - QUICK START GUIDE         ║
║                          VISUAL REFERENCE v1.0                             ║
╚════════════════════════════════════════════════════════════════════════════╝

┌─ STEP 1: RUN THE SCRIPT ─────────────────────────────────────────────────┐
│                                                                            │
│  $ python BERT_base_IMDB.py                                              │
│                                                                            │
│  A menu will appear with options:                                         │
│    1. Phase 1: Sensitivity Analysis                                       │
│    2. Phase 2: Quantization & Evaluation                                  │
│    3. Run both phases (RECOMMENDED for first time)                        │
│    4. Exit                                                                │
│                                                                            │
│  Select option 3 to run everything in sequence.                          │
│                                                                            │
└────────────────────────────────────────────────────────────────────────────┘

┌─ STEP 2: PHASE 1 - SENSITIVITY ANALYSIS ────────────────────────────────┐
│                                                                            │
│  ┌─ Question 1: Calibration Size ──────────────────────────────────────┐ │
│  │  How much data to compute sensitivities from?                       │ │
│  │                                                                      │ │
│  │  → For QUICK TEST (recommended):                                    │ │
│  │    Select: "5k (fast, noisy)"  [takes ~3 minutes]                  │ │
│  │                                                                      │ │
│  │  → For FINAL RESULTS (recommended):                                │ │
│  │    Select: "25k (full IMDB train, recommended)"  [takes ~10 min]   │ │
│  │                                                                      │ │
│  └──────────────────────────────────────────────────────────────────────┘ │
│                                                                            │
│  ┌─ Question 2: Sampling Strategy ─────────────────────────────────────┐ │
│  │  How to select examples from calibration data?                     │ │
│  │                                                                      │ │
│  │  ✓ ALWAYS SELECT: "Stratified sampling (recommended)"              │ │
│  │                                                                      │ │
│  │    (Balances positive/negative examples for better coverage)       │ │
│  │                                                                      │ │
│  └──────────────────────────────────────────────────────────────────────┘ │
│                                                                            │
│  ┌─ Question 3: Similarity Metrics ────────────────────────────────────┐ │
│  │  Which metrics for measuring layer similarity?                     │ │
│  │                                                                      │ │
│  │  ✓ RECOMMENDED: "PWCCA + CKA (recommended)"                         │ │
│  │    - PWCCA: Fast, standard approach                                │ │
│  │    - CKA: Robust verification metric                              │ │
│  │    - Together: Best reliability                                    │ │
│  │                                                                      │ │
│  │  Other options:                                                     │ │
│  │  • "PWCCA only" - Just PWCCA (faster)                             │ │
│  │  • "SVCCA only" - Alternative metric                              │ │
│  │  • "CKA only" - Robust but slower                                 │ │
│  │  • "All three" - Thorough analysis (slowest)                      │ │
│  │                                                                      │ │
│  └──────────────────────────────────────────────────────────────────────┘ │
│                                                                            │
│  OUTPUT: Sensitivity scores for each layer                               │
│          (higher = more important → allocate more bits)                  │
│                                                                            │
│  Files saved to: Sensitivities/                                          │
│  • layer_sensitivity_BERT_IMDB_pwcca.json  ← Use in Phase 2              │
│  • layer_sensitivity_BERT_IMDB_pwcca.txt   ← Human-readable              │
│                                                                            │
└────────────────────────────────────────────────────────────────────────────┘

┌─ STEP 3: PHASE 2 - QUANTIZATION & EVALUATION ───────────────────────────┐
│                                                                            │
│  ┌─ Question 1: Evaluation Set Size ──────────────────────────────────┐ │
│  │  How much test data to evaluate on?                               │ │
│  │                                                                      │ │
│  │  → For QUICK FEEDBACK:                                             │ │
│  │    Select: "5k (fast iteration)"  [takes ~2 minutes]              │ │
│  │                                                                      │ │
│  │  → For FINAL NUMBERS (recommended):                               │ │
│  │    Select: "25k (full test, recommended)"  [takes ~5 minutes]     │ │
│  │                                                                      │ │
│  └──────────────────────────────────────────────────────────────────────┘ │
│                                                                            │
│  ┌─ Question 2: Clustering Strategy ──────────────────────────────────┐ │
│  │  How to group layers by sensitivity?                             │ │
│  │                                                                      │ │
│  │  ✓ ALWAYS SELECT: "K-means (recommended)"                          │ │
│  │                                                                      │ │
│  │    Automatically groups similar layers together                   │ │
│  │    (other options: Percentile, Hierarchical)                      │ │
│  │                                                                      │
│  └──────────────────────────────────────────────────────────────────────┘ │
│                                                                            │
│  ┌─ Question 3: Number of Groups ─────────────────────────────────────┐ │
│  │  How many precision levels to use?                                │ │
│  │                                                                      │ │
│  │  → For QUICK TEST:                                                 │ │
│  │    Select: "3 groups (simpler)"                                   │ │
│  │                                                                      │ │
│  │  → For BETTER ACCURACY (recommended):                              │ │
│  │    Select: "4 groups (finer control)"                             │ │
│  │                                                                      │ │
│  │  3 vs 4 groups: When to use which?                                │ │
│  │  ┌────────────────────────────────────────┐                        │ │
│  │  │ 3 groups: Good compression, simpler     │                        │ │
│  │  │           (~2.0x smaller)               │                        │ │
│  │  │           ~1-2% accuracy drop           │                        │ │
│  │  ├────────────────────────────────────────┤                        │ │
│  │  │ 4 groups: Better accuracy, more control │                        │ │
│  │  │           (~1.5x smaller)               │                        │ │
│  │  │           <1% accuracy drop             │                        │ │
│  │  └────────────────────────────────────────┘                        │ │
│  │                                                                      │ │
│  │  DECISION RULE:                                                     │ │
│  │  Start with 3 groups → If accuracy drops >2%, try 4 groups        │ │
│  │                                                                      │ │
│  └──────────────────────────────────────────────────────────────────────┘ │
│                                                                            │
│  ┌─ Question 4: Bit Allocation ───────────────────────────────────────┐ │
│  │  How many bits for each cluster?                                  │ │
│  │                                                                      │ │
│  │  For 3 GROUPS:                                                     │ │
│  │  ┌─────────────────────────────────────────┐                       │ │
│  │  │ ✓ [16, 8, 4]  ← RECOMMENDED            │                       │ │
│  │  │   (Good balance)                        │                       │ │
│  │  │   Expected: 1-2% drop, 2.0x compression│                       │ │
│  │  ├─────────────────────────────────────────┤                       │ │
│  │  │ [8, 4, 2]  (Aggressive compression)    │                       │ │
│  │  │   Expected: 5-10% drop, 4.0x           │                       │ │
│  │  └─────────────────────────────────────────┘                       │ │
│  │                                                                      │ │
│  │  For 4 GROUPS:                                                     │ │
│  │  ┌─────────────────────────────────────────┐                       │ │
│  │  │ ✓ [32, 16, 8, 4]  ← RECOMMENDED        │                       │ │
│  │  │   (Conservative, keeps top layers safe) │                       │ │
│  │  │   Expected: <1% drop, 1.5x compression │                       │ │
│  │  ├─────────────────────────────────────────┤                       │ │
│  │  │ [16, 8, 4, 2]  (Moderate)              │                       │ │
│  │  │   Expected: 1-2% drop, 2.5x            │                       │ │
│  │  ├─────────────────────────────────────────┤                       │ │
│  │  │ [8, 4, 2, 2]  (Aggressive)             │                       │ │
│  │  │   Expected: 5-10% drop, 4.0x           │                       │ │
│  │  └─────────────────────────────────────────┘                       │ │
│  │                                                                      │ │
│  └──────────────────────────────────────────────────────────────────────┘ │
│                                                                            │
│  OUTPUT: Detailed evaluation report                                      │
│  • FP32 baseline metrics (before quantization)                           │
│  • Quantized model metrics (after quantization)                          │
│  • Accuracy drop percentage                                              │
│  • Model size reduction                                                  │
│  • Compression ratio                                                     │
│                                                                            │
│  Files saved to: Evaluation/                                             │
│  • eval_BERT_IMDB_kmeans_3groups_[TIMESTAMP].txt                         │
│                                                                            │
└────────────────────────────────────────────────────────────────────────────┘

╔════════════════════════════════════════════════════════════════════════════╗
║                         EXPECTED RESULTS BY SCENARIO                       ║
╚════════════════════════════════════════════════════════════════════════════╝

┌─ SCENARIO 1: QUICK TEST (5 minutes) ─────────────────────────────────────┐
│                                                                            │
│  Configuration:                                                           │
│  • Calibration: 5k samples                                               │
│  • Metric: PWCCA + CKA                                                   │
│  • Clusters: 3 groups, [16/8/4] bits                                     │
│  • Evaluation: 5k samples                                                │
│                                                                            │
│  Expected Results:                                                       │
│  ✓ Time: ~5 minutes                                                      │
│  ✓ Accuracy drop: 2-3%                                                   │
│  ✓ Size reduction: 2.0x (50% smaller)                                    │
│  ✓ Original: 52.38 MB → Quantized: 26.19 MB                              │
│                                                                            │
│  Use case: Prototyping, exploring ideas, quick feedback                 │
│                                                                            │
└────────────────────────────────────────────────────────────────────────────┘

┌─ SCENARIO 2: BALANCED (15 minutes) ──────────────────────────────────────┐
│                                                                            │
│  Configuration:                                                           │
│  • Calibration: 25k samples (full TRAIN)                                │
│  • Metric: PWCCA + CKA                                                   │
│  • Clusters: 3 groups, [16/8/4] bits                                     │
│  • Evaluation: 10k samples                                               │
│                                                                            │
│  Expected Results:                                                       │
│  ✓ Time: ~15 minutes                                                     │
│  ✓ Accuracy drop: 1-2% (more stable)                                     │
│  ✓ Size reduction: 2.0x (50% smaller)                                    │
│  ✓ Confidence: High (larger calib set)                                   │
│                                                                            │
│  Use case: Production runs, validation                                   │
│                                                                            │
└────────────────────────────────────────────────────────────────────────────┘

┌─ SCENARIO 3: FINAL RESULTS (30 minutes) ────────────────────────────────┐
│                                                                            │
│  Configuration:                                                           │
│  • Calibration: 25k samples (full TRAIN)                                │
│  • Metric: PWCCA + CKA                                                   │
│  • Clusters: 4 groups, [32/16/8/4] bits                                 │
│  • Evaluation: 25k samples (full TEST)                                  │
│                                                                            │
│  Expected Results:                                                       │
│  ✓ Time: ~30 minutes                                                     │
│  ✓ Accuracy drop: <1% (excellent!)                                       │
│  ✓ Size reduction: 1.5x (33% smaller)                                    │
│  ✓ Confidence: Very high (full dataset)                                  │
│                                                                            │
│  Use case: Publication, benchmark reports, deployment                   │
│                                                                            │
└────────────────────────────────────────────────────────────────────────────┘

╔════════════════════════════════════════════════════════════════════════════╗
║                         WHEN TO USE WHAT: DECISION TREE                    ║
╚════════════════════════════════════════════════════════════════════════════╝

                            START HERE
                                ↓
                    How much time do you have?
                    /              │              \
                   /               │               \
              5 min           15 min           30+ min
               ↓                ↓                  ↓
            QUICK         BALANCED         FINAL RESULTS
              ↓                ↓                  ↓
         ┌─────────┐   ┌──────────────┐  ┌──────────────┐
         │ 5k cal  │   │ 25k cal      │  │ 25k cal      │
         │ 3 groups│   │ 3 groups     │  │ 4 groups     │
         │[16/8/4] │   │ [16/8/4]     │  │[32/16/8/4]   │
         │ 5k test │   │ 10k test     │  │ 25k test     │
         └─────────┘   └──────────────┘  └──────────────┘
            ↓                ↓                  ↓
         DROP: 2-3%      DROP: 1-2%       DROP: <1%
         RATIO: 2.0x     RATIO: 2.0x      RATIO: 1.5x
         FAST            BALANCED         BEST

╔════════════════════════════════════════════════════════════════════════════╗
║                              TROUBLESHOOTING                               ║
╚════════════════════════════════════════════════════════════════════════════╝

Problem: Accuracy dropped too much (>5%)
→ Solution: Use [32, 16, 8, 4] instead of [16, 8, 4]
→ Solution: Use 4 groups instead of 3
→ Solution: Increase calibration size (10k → 25k)

Problem: Script is running too slow
→ Solution: Use 5k calibration/evaluation instead of 25k
→ Solution: Reduce num_workers in DataLoader
→ Solution: Close other GPU processes

Problem: Files not found in Phase 2
→ Solution: Make sure Phase 1 completed successfully
→ Solution: Check Sensitivities/ directory exists
→ Solution: Run Phase 1 again if needed

Problem: Out of memory error
→ Solution: Reduce batch size (modify script)
→ Solution: Use smaller dataset (5k instead of 25k)
→ Solution: Run on CPU (slower but uses system RAM)

╔════════════════════════════════════════════════════════════════════════════╗
║                              OUTPUT LOCATIONS                              ║
╚════════════════════════════════════════════════════════════════════════════╝

Phase 1 outputs → Sensitivities/ directory
├── layer_sensitivity_BERT_IMDB_pwcca.json     ← Raw JSON
├── layer_sensitivity_BERT_IMDB_pwcca.txt      ← Human readable
├── layer_sensitivity_BERT_IMDB_svcca.json
└── ...

Phase 2 outputs → Evaluation/ directory
├── eval_BERT_IMDB_kmeans_3groups_20250113_142530.txt
├── eval_BERT_IMDB_hierarchical_4groups_20250113_150102.txt
└── ...

Sample Phase 2 output contains:
├── FP32 baseline metrics
├── Quantized model metrics
├── Accuracy drops and impact analysis
├── Compression statistics
└── Layer-by-layer bit allocation

╔════════════════════════════════════════════════════════════════════════════╗
║                              KEY TAKEAWAYS                                 ║
╚════════════════════════════════════════════════════════════════════════════╝

✓ Always use STRATIFIED SAMPLING (question 2 in Phase 1)

✓ Use PWCCA + CKA together (best metrics combination)

✓ Start with K-means clustering (default, works well)

✓ Choose configuration based on time/accuracy tradeoff:
  - Quick test: 5k, 3 groups, [16/8/4]
  - Final: 25k, 4 groups, [32/16/8/4]

✓ If accuracy drops >2%:
  - Increase bits (e.g., 32 instead of 16)
  - Use 4 groups instead of 3
  - Increase calibration size

✓ All outputs are saved with timestamps for tracking

✓ Read README_BERT_base_IMDB.md for detailed documentation

✓ Check config_reference.py for preset configurations

╔════════════════════════════════════════════════════════════════════════════╗
║                           QUICK REFERENCE METRICS                          ║
╚════════════════════════════════════════════════════════════════════════════╝

┌─ Accuracy Drop Interpretation ──────────────────────────────────────────┐
│  < 1%    ✓ Excellent  - Use this configuration!                        │
│  1-2%    ✓ Good       - Acceptable for most use cases                  │
│  2-3%    ⚠ Moderate   - Consider increasing bits                       │
│  3-5%    ⚠ Large      - Adjust: more bits, more clusters, or QAT       │
│  > 5%    ✗ Very large - Need to change approach                        │
└────────────────────────────────────────────────────────────────────────────┘

┌─ Compression Ratios ────────────────────────────────────────────────────┐
│  1.3x    Conservative - Small size reduction, minimal accuracy loss    │
│  1.5x    Good         - 33% size reduction, <1% accuracy loss          │
│  2.0x    Balanced     - 50% size reduction, 1-2% accuracy loss         │
│  3.0x    Aggressive   - 67% size reduction, 3-5% accuracy loss         │
│  4.0x+   Very agg.    - 75%+ size reduction, 5%+ accuracy loss         │
└────────────────────────────────────────────────────────────────────────────┘

═══════════════════════════════════════════════════════════════════════════════

For detailed documentation, see:
  • README_BERT_base_IMDB.md      ← Full user guide
  • BERT_QUICK_REFERENCE.txt      ← Text-based quick reference
  • config_reference.py           ← Configuration presets
  • IMPLEMENTATION_SUMMARY.txt    ← What was built

Version: 1.0.0
Status: Ready to use ✓
Last Updated: January 13, 2025

═══════════════════════════════════════════════════════════════════════════════
